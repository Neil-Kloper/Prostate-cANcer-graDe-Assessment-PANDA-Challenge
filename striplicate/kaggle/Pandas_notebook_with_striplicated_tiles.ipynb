{"cells":[{"metadata":{},"cell_type":"markdown","source":"For sharing with others, I adapted this program to run on kaggle, but you would probably be better off converting training images elsewhere.\n\nThe purpose of this program is to create a set of images which are composed of a set of image tiles, and to then fill in most whitespace between tiles with other portions of the image.\n\nThis program uses image tile generation methods that I found on Kaggle, (https://www.kaggle.com/rftexas/better-image-tiles-removing-white-spaces).  Then it uses my methods to remove most of the remaining white space.  It replaces the white space with other portions of the image.  The recipe I used to accomplish this is crude and inefficient.  It could be made a lot smarter about defining what white space is, knowing where it resides, and using fewer loops to overwrite it.\n\nI have an earlier version of the program that does not use tiles.  It simply copies non-whitespace data into white space areas, in the hope that most images will eventually have little to no white space, but it doesn't check for that.\n\nSome of the code below is unused and is not needed here, as I just borrowed sections of code from an early version of one of our competition notebooks.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport time\nimport gc\nimport cv2\nimport PIL\nimport random\nimport openslide\nimport skimage.io\nfrom skimage.transform import rescale, resize, downscale_local_mean\nimport matplotlib\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image, display\n\n# from torch import cuda\n\nfrom multiprocessing import Pool\n\n# import cupy as cp\n\"\"\" My first version worked ok with cupy and multiprocessing, but \n    In this program, I encountered known limitations that I didn't try to fix \n\"\"\"","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"\" My first version worked ok with cupy and multiprocessing, but \\n    In this program, I encountered known limitations that I didn't try to fix \\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nfrom fastai import *\nfrom fastai.vision import *","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/train.csv')\ntrain[['primary Gleason', 'secondary Gleason']] = train.gleason_score.str.split('+',expand=True)\ndisplay(train.head())\n\ntest = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/test.csv')\ndisplay(test)\n\nsubmission = pd.read_csv('/kaggle/input/prostate-cancer-grade-assessment/sample_submission.csv')\nsubmission\n\ntrain['id'] = train['image_id'] + '.jpeg'\ntrain_isup = train[['id', 'isup_grade']]\ntrain_primary = train[['id', 'primary Gleason']]\ntrain_secondary = train[['id', 'secondary Gleason']]","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"                           image_id data_provider  isup_grade gleason_score  \\\n0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0   \n1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0   \n2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4   \n3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4   \n4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0   \n\n  primary Gleason secondary Gleason  \n0               0                 0  \n1               0                 0  \n2               4                 4  \n3               4                 4  \n4               0                 0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n      <th>isup_grade</th>\n      <th>gleason_score</th>\n      <th>primary Gleason</th>\n      <th>secondary Gleason</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0005f7aaab2800f6170c399693a96917</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n      <td>radboud</td>\n      <td>4</td>\n      <td>4+4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n      <td>karolinska</td>\n      <td>4</td>\n      <td>4+4</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n      <td>karolinska</td>\n      <td>0</td>\n      <td>0+0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                           image_id data_provider\n0  005700be7e06878e6605e7a5a39de1b2       radboud\n1  005c6e8877caf724c600fdce5d417d40    karolinska\n2  0104f76634ff89bfff1ef0804a95c380       radboud","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>data_provider</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>005700be7e06878e6605e7a5a39de1b2</td>\n      <td>radboud</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005c6e8877caf724c600fdce5d417d40</td>\n      <td>karolinska</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0104f76634ff89bfff1ef0804a95c380</td>\n      <td>radboud</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = list(train['image_id'])\nimages.append(list(test['image_id']))\nlabels = list(train['isup_grade'])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.exists('/kaggle/working/images-tiled-striplicated'):\n    os.mkdir('images-tiled-striplicated')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\nsample_submission = pd.read_csv('../input/prostate-cancer-grade-assessment/sample_submission.csv')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/prostate-cancer-grade-assessment/train_images/'\n\n# compute_statistics was copied from: \n#    https://www.kaggle.com/rftexas/better-image-tiles-removing-white-spaces\ndef compute_statistics(image):\n    \"\"\"\n    Args:\n        image                  numpy.array   multi-dimensional array of the form WxHxC\n    \n    Returns:\n        ratio_white_pixels     float         ratio of white pixels over total pixels in the image \n    \"\"\"\n    width, height = image.shape[0], image.shape[1]\n    num_pixels = width * height\n    \n    num_white_pixels = 0\n    \n    summed_matrix = np.sum(image, axis=-1)\n    # Note: A 3-channel white pixel has RGB (255, 255, 255)\n    num_white_pixels = np.count_nonzero(summed_matrix > 620)\n    ratio_white_pixels = num_white_pixels / num_pixels\n    \n    green_concentration = np.mean(image[1])\n    blue_concentration = np.mean(image[2])\n    \n    return ratio_white_pixels, green_concentration, blue_concentration\n\n\n# select_k_best_regions was copied from: \n#    https://www.kaggle.com/rftexas/better-image-tiles-removing-white-spaces\ndef select_k_best_regions(regions, k=20):\n    \"\"\"\n    Args:\n        regions               list           list of 2-component tuples first component the region, \n                                             second component the ratio of white pixels\n                                             \n        k                     int            number of regions to select\n    \"\"\"\n    regions = [x for x in regions if x[3] > 180 and x[4] > 180]\n    k_best_regions = sorted(regions, key=lambda tup: tup[2])[:k]\n    return k_best_regions\n\n# get_k_best_regions was copied from: \n#    https://www.kaggle.com/rftexas/better-image-tiles-removing-white-spaces\ndef get_k_best_regions(coordinates, image, window_size=1024):#window size 512 is default\n    regions = {}\n    for i, tup in enumerate(coordinates):\n        x, y = tup[0], tup[1]\n        regions[i] = image[x : x+window_size, y : y+window_size, :]\n    \n    return regions\n\n# generate_patches was copied from: \n#    https://www.kaggle.com/rftexas/better-image-tiles-removing-white-spaces\ndef generate_patches(slide_path, window_size=200, stride=256, k=20):#stride 128\n    \n    image = skimage.io.MultiImage(slide_path)[-2]\n    image = np.array(image)\n    \n    max_width, max_height = image.shape[0], image.shape[1]\n    regions_container = []\n    i = 0\n    \n    while window_size + stride*i <= max_height:\n        j = 0\n        \n        while window_size + stride*j <= max_width:            \n            x_top_left_pixel = j * stride\n            y_top_left_pixel = i * stride\n            \n            patch = image[\n                x_top_left_pixel : x_top_left_pixel + window_size,\n                y_top_left_pixel : y_top_left_pixel + window_size,\n                :\n            ]\n            \n            ratio_white_pixels, green_concentration, blue_concentration = compute_statistics(patch)\n            \n            region_tuple = (x_top_left_pixel, y_top_left_pixel, ratio_white_pixels, green_concentration, blue_concentration)\n            regions_container.append(region_tuple)\n            \n            j += 1\n        \n        i += 1\n    \n    k_best_region_coordinates = select_k_best_regions(regions_container, k=k)\n    k_best_regions = get_k_best_regions(k_best_region_coordinates, image, window_size)\n    \n    return image, k_best_region_coordinates, k_best_regions\n\n\n# display_images was copied from: \n#    https://www.kaggle.com/rftexas/better-image-tiles-removing-white-spaces\ndef display_images(regions, title):\n    fig, ax = plt.subplots(5, 4, figsize=(15, 15))\n    \n    for i, region in regions.items():\n        ax[i//4, i%4].imshow(region)\n    \n    fig.suptitle(title)\n    \n\n# glue_to_one_picture was copied from: \n#    https://www.kaggle.com/rftexas/better-image-tiles-removing-white-spaces\ndef glue_to_one_picture(image_patches, window_size=200, k=32):\n    side = int(np.sqrt(k))\n    image = np.zeros((side*window_size, side*window_size, 3), dtype=np.int16)\n        \n    for i, patch in image_patches.items():\n        x = i // side\n        y = i % side\n        image[\n            x * window_size : (x+1) * window_size,\n            y * window_size : (y+1) * window_size,\n            :\n        ] = patch\n    \n    return image","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_center(img,cropx,cropy):\n    y,x,z = img.shape\n    startx = x//2-(cropx//2)\n    starty = y//2-(cropy//2)    \n    return img[starty:starty+cropy,startx:startx+cropx,:z]","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def slur(image, n):\n    \"\"\"\n    make a copy of the image, shift and write wherever there is white space.\n    \"\"\"\n\n    r1, g1, b1 = 214, 214, 214 \n    r2, g2, b2 = 255, 255, 255\n    red, green, blue = image[n:,:,0], image[n:,:,1], image[n:,:,2]\n    mask = (red >= r1) & (green >= g1) & (blue >= b1)\n    \n    # not sure why I wrote the next line of code.  Perhaps I was low on caffeine\n    # I'll think later, but this looks buggly.\n    image[n:,:,:3][mask] = [r2, g2, b2]\n    \n    slurred = np.copy(image)\n#     slurred = cp.copy(image)\n#     cp.cuda.Stream.null.synchronize()\n\n    \n    if n >= 0:\n        slurred[n:,:,:3][mask] = image[:-n,:,:3][mask]\n        \n    # at one point there was a horrible memory leak, so I started\n    # calling del. Something made the problem go away, but I didn't root cause it.\n    del image\n    del mask\n    del red\n    del green\n    del blue\n    print('.', end='')\n    return slurred","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def striplicate(npimage):\n    \"\"\"\n    Set whiteness in r1,g1,g1\n    \n    logically divide the image into stripes.\n    stripes are grouped columns of stripe_size, \n    which is cols divided by some smaller number.\n        \n    make a rotated copy of an image, and then use that to\n    kickstart the process of slur()'ing over the white space.\n    \n    \"\"\"\n    \n    # image = cp.copy(npimage)\n    image = np.copy(npimage)\n    # cp.cuda.Stream.null.synchronize()\n    # help(cp.cuda.Stream.null)\n    rimage = np.rot90(image, k=1)\n    # rimage = cp.rot90(image, k=1)\n    # cp.cuda.Stream.null.synchronize()\n        \n    r1, g1, b1 = 212, 212, 212 # Original value for whiteness\n    r2, g2, b2 = 255, 255, 255 # Value to replace it with\n   \n    red, green, blue = image[:,:,0], image[:,:,1], image[:,:,2]\n    rred, rgreen, rblue = rimage[:,:,0], rimage[:,:,1], rimage[:,:,2]\n    \n    mask = (red >= r1) & (green >= g1) & (blue >= b1)\n    rmask =(rred >= r1) & (rgreen >= g1) & (rblue >= b1)\n        \n    rimage[:,:,:3][rmask] = [r2, g2, b2]\n    del rmask\n    rows,cols,depth = rimage.shape\n\n    stripe_size = cols//6\n    simage = None\n    for stripe in range(stripe_size, cols, stripe_size):\n        # print(f'stripe: {stripe}, cols: {cols}')\n        if simage is not None:\n            simage = slur(simage, stripe_size)\n        else:\n            simage = slur(rimage, stripe_size)\n            del rimage\n            \n    stripe_size = cols//3\n    \n    simage = np.rot90(simage, k=1)\n    # simage = cp.rot90(simage, k=1)\n    # cp.cuda.Stream.null.synchronize()\n\n    for stripe in range(stripe_size, cols, stripe_size):\n        # print(f'stripe: {stripe}, cols: {cols}')\n        if simage is not None:\n            simage = slur(simage, stripe_size)\n        else:\n            simage = slur(rimage, stripe_size)\n            del rimage\n            \n    stripe_size = cols//2      \n    simage = np.rot90(simage, k=1)\n    # simage = cp.rot90(simage, k=1)\n    # cp.cuda.Stream.null.synchronize()\n\n    for stripe in range(stripe_size, cols, stripe_size):\n        # print(f'stripe: {stripe}, cols: {cols}')\n        if simage is not None:\n            simage = slur(simage, stripe_size)\n        else:\n            simage = slur(rimage, stripe_size)\n            del rimage\n    \n    stripe_size = cols//2\n    simage = np.rot90(simage, k=1)\n    # simage = cp.rot90(simage, k=1)\n    # cp.cuda.Stream.null.synchronize()\n    for stripe in range(stripe_size, cols, stripe_size):\n        # print(f'stripe: {stripe}, cols: {cols}')\n        if simage is not None:\n            simage = slur(simage, stripe_size)\n        else:\n            simage = slur(rimage, stripe_size)\n            del rimage\n\n    stripe_size = cols//2\n    simage = np.rot90(simage, k=1)\n    # simage = cp.rot90(simage, k=1)\n    # cp.cuda.Stream.null.synchronize()\n\n    for stripe in range(stripe_size, cols, stripe_size):\n        # print(f'stripe: {stripe}, cols: {cols}')\n        if simage is not None:\n            simage = slur(simage, stripe_size)\n        else:\n            simage = slur(rimage, stripe_size)\n            del rimage\n\n            \n    print(f'simage shape: {simage.shape}')\n\n\n    image[:,:,:3][mask] = [r2, g2, b2]\n    image[:,:,:3][mask] = simage[:,:,:3][mask]\n\n    return image\n#     return crop_center(image, 2048, 2048)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"WINDOW_SIZE = 256\nSTRIDE = 128\nK = 4","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_images(range_list):\n    print(f'range_list: {range_list}')\n    starting_index, ending_index = range_list\n\n    for counter, img in enumerate(images):\n        if counter > 16:  # limit this for test purposes.\n            continue\n\n        if counter < starting_index or counter > ending_index or os.path.isfile(f'images-tiled-striplicated/{img}.jpeg'):\n            continue\n#         print(f'{counter}', end=', ')\n\n        \n     \n        fig, ax = plt.subplots(6, 2, figsize=(20, 25))\n\n        url = data_dir + img + '.tiff'\n        print(url)\n        \n        image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n        \n        glued_image = glue_to_one_picture(best_regions, window_size=WINDOW_SIZE, k=K)\n        simage = striplicate(np.array(glued_image, dtype=np.uint8))\n        npImage = np.array(simage, dtype=np.uint8)\n\n        plt.imsave(f'images-tiled-striplicated/{img}.jpeg', npImage, format='jpg')\n        \n        plt.close()\n        del npImage\n        del glued_image\n        del fig\n        del ax\n        del best_coordinates\n        del best_regions\n        gc.collect()","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will take a very long time.\nnprocs=6   # nprocs over 16, swamps my home computer.\nend=10620  # just some number a little bigger than total number of images.\ngroup_len = end//nprocs\nstart=0\n# multiprocessing.set_start_method('spawn')\n# ctx = multiprocessing.get_context('spawn')\n# multiprocessing.set_start_method('fork')\n\nrange_list = list()\n\nfor i in range(1,nprocs+1):\n    end = group_len * i\n    range_list.append([start, end])\n    start = end\n\nwith Pool(nprocs) as workers:\n    w = list(workers.map(process_images, range_list))\n    print(w)\n    \nprint(\"it's Miller time!\")","execution_count":14,"outputs":[{"output_type":"stream","text":"range_list: [5310, 7080]\nrange_list: [3540, 5310]\nrange_list: [0, 1770]\nrange_list: [1770, 3540]\nrange_list: [7080, 8850]\nrange_list: [8850, 10620]\n../input/prostate-cancer-grade-assessment/train_images/0005f7aaab2800f6170c399693a96917.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/000920ad0b612851f8e01bcc880d9b3d.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/0018ae58b01bdadc8e347995b69f99aa.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/001c62abd11fa4b57bf7a6c603a11bb9.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/001d865e65ef5d2579c190a0e0350d8f.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/002a4db09dad406c85505a00fb6f6144.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/003046e27c8ead3e3db155780dc5498e.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/0032bfa835ce0f43a92ae0bbab6871cb.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/003a91841da04a5a31f808fb5c21538a.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/003d4dd6bd61221ebc0bfb9350db333f.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/00412139e6b04d1e1cee8421f38f6e90.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/004391d48d58b18156f811087cd38abf.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/004dd32d9cd167d9cc31c13b704498af.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/004f6b3a66189b4e88b6a01ba19d7d31.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/005e66f06bce9c2e49142536caf2f6ee.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/0068d4c7529e34fd4c9da863ce01a161.tiff\n............simage shape: (512, 512, 3)\n../input/prostate-cancer-grade-assessment/train_images/006f4d8d3556dd21f6424202c2d294a9.tiff\n............simage shape: (512, 512, 3)\n[None, None, None, None, None, None]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}