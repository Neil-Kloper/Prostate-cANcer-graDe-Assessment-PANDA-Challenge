{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Final Submission\n",
    "\n",
    "This notebook is an edited version of our final submission to the PANDAS challenge. This notebook takes the images in the test set and converts them from .tiff to .jpeg, then it breaks the image down into a series of tiles, after which it stitches together the top tiles 25 tiles based on the least amount of blank space in the tile. Once the images are preprocessed, they are fed to a series of models and the results averaged to get the final prediction (more on this in our model blend evaluation notebook). Our top submission, put together by Eliot, used four high performing models."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<a id=\"ToC\"></a>\n",
    "# Table of contents\n",
    "\n",
    "[Create Models](#part-one) Add or remove models from the blend\n",
    "\n",
    "[Image Preprocessing](#part-two)\n",
    "\n",
    "[Inference Function](#part-three)\n",
    "\n",
    "[Run Inference](#part-four) See here for testing combonations of models and veiwing performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "import random\n",
    "import openslide\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>primary Gleason</th>\n",
       "      <th>secondary Gleason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score  \\\n",
       "0  0005f7aaab2800f6170c399693a96917    karolinska           0           0+0   \n",
       "1  000920ad0b612851f8e01bcc880d9b3d    karolinska           0           0+0   \n",
       "2  0018ae58b01bdadc8e347995b69f99aa       radboud           4           4+4   \n",
       "3  001c62abd11fa4b57bf7a6c603a11bb9    karolinska           4           4+4   \n",
       "4  001d865e65ef5d2579c190a0e0350d8f    karolinska           0           0+0   \n",
       "\n",
       "  primary Gleason secondary Gleason  \n",
       "0               0                 0  \n",
       "1               0                 0  \n",
       "2               4                 4  \n",
       "3               4                 4  \n",
       "4               0                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### DataFrames\n",
    "\n",
    "path = Path('/kaggle/input/pandas-to-jpeg-with-tiles-sample')\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "train = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv')\n",
    "train[['primary Gleason', 'secondary Gleason']] = train.gleason_score.str.split('+',expand=True)\n",
    "display(train.head())\n",
    "\n",
    "train['id'] = train['image_id'] + '.jpeg'\n",
    "train_isup = train[['id', 'isup_grade']]\n",
    "train_primary = train[['id', 'primary Gleason']]\n",
    "train_secondary = train[['id', 'secondary Gleason']]\n",
    "\n",
    "train_isup['isup_grade'] = train_isup['isup_grade'].astype(int)\n",
    "\n",
    "\n",
    "train_isup['grade_1'] = pd.Series([1 if x >= 1 else 0 for x in train_isup['isup_grade']], index=train_isup.index)\n",
    "train_isup['grade_2'] = pd.Series([1 if x >= 2 else 0 for x in train_isup['isup_grade']], index=train_isup.index)\n",
    "train_isup['grade_3'] = pd.Series([1 if x >= 3 else 0 for x in train_isup['isup_grade']], index=train_isup.index)\n",
    "train_isup['grade_4'] = pd.Series([1 if x >= 4 else 0 for x in train_isup['isup_grade']], index=train_isup.index)\n",
    "train_isup['grade_5'] = pd.Series([1 if x >= 5 else 0 for x in train_isup['isup_grade']], index=train_isup.index)\n",
    "\n",
    "train_bin = train_isup[['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5']]\n",
    "\n",
    "test_df = pd.read_csv('../input/prostate-cancer-grade-assessment/test.csv')\n",
    "sample_submission = pd.read_csv('../input/prostate-cancer-grade-assessment/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<a id=\"part-one\"></a>\n",
    "# Create Models\n",
    "\n",
    "Object data is a databunch object which resizes all input images to size 448, data_512 resizes all input images to size 512, data_686 uses size 686, and so on and so fourth. The commented out codeblocks contain models that were not selected to be part of our final submission.\n",
    "\n",
    "[Return to Table of Contents](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOW_SIZE = 200 ### Values for merge large dataset\n",
    "# STRIDE = 100\n",
    "# K = 25\n",
    "\n",
    "\n",
    "data = ImageDataBunch.from_df(path=Path('/kaggle/input/pandas-to-jpeg-with-tiles-sample'),\n",
    "                              df=train_bin.loc[:1000], #train_isup (the actual target), train_primary, train_secondary\n",
    "                              valid_pct=0.25,\n",
    "                              label_col=['grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'],\n",
    "                              size=448,\n",
    "                              bs=8,\n",
    "                              ds_tfms=get_transforms()\n",
    "        ).normalize(imagenet_stats)\n",
    "\n",
    "data_512 = ImageDataBunch.from_df(path=Path('/kaggle/input/pandas-to-jpeg-with-tiles-sample'),\n",
    "                              df=train_bin.loc[:1000], #train_isup (the actual target), train_primary, train_secondary\n",
    "                              valid_pct=0.25,\n",
    "                              label_col=['grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'],\n",
    "                              size=512,\n",
    "                              bs=8,\n",
    "                              ds_tfms=get_transforms()\n",
    "        ).normalize(imagenet_stats)\n",
    "\n",
    "data_686 = ImageDataBunch.from_df(path=Path('/kaggle/input/pandas-to-jpeg-with-tiles-sample'),\n",
    "                              df=train_bin.loc[:1000], #train_isup (the actual target), train_primary, train_secondary\n",
    "                              valid_pct=0.25,\n",
    "                              label_col=['grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'],\n",
    "                              size=686,\n",
    "                              bs=8,\n",
    "                              ds_tfms=get_transforms()\n",
    "        ).normalize(imagenet_stats)\n",
    "\n",
    "data_784 = ImageDataBunch.from_df(path=Path('/kaggle/input/pandas-to-jpeg-with-tiles-sample'),\n",
    "                              df=train_bin.loc[:1000], #train_isup (the actual target), train_primary, train_secondary\n",
    "                              valid_pct=0.25,\n",
    "                              label_col=['grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'],\n",
    "                              size=784,\n",
    "                              bs=4,\n",
    "                              ds_tfms=get_transforms()\n",
    "        ).normalize(imagenet_stats)\n",
    "data_616 = ImageDataBunch.from_df(path=Path('/kaggle/input/pandas-to-jpeg-with-tiles-sample'),\n",
    "                              df=train_bin.loc[:1000], #train_isup (the actual target), train_primary, train_secondary\n",
    "                              valid_pct=0.25,\n",
    "                              label_col=['grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'],\n",
    "                              size=616,\n",
    "                              bs=10,\n",
    "                              ds_tfms=get_transforms()\n",
    "        ).normalize(imagenet_stats)                                  \n",
    "data_840 = ImageDataBunch.from_df(path=Path('/kaggle/input/pandas-to-jpeg-with-tiles-sample'),\n",
    "                              df=train_bin.loc[:1000], #train_isup (the actual target), train_primary, train_secondary\n",
    "                              valid_pct=0.25,\n",
    "                              label_col=['grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'],\n",
    "                              size=840,\n",
    "                              bs=8,\n",
    "                              ds_tfms=get_transforms()                                  \n",
    "                                  \n",
    "                                  \n",
    "        ).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Model objects:\n",
    "The cells below instantiate each model that is used for inference. To add new models simply copy one of the cells below and modify the object name, model path, Databunch, and load name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners = [] #this variable will hold a list of models that will be iterated through at inference time\n",
    "learner_dfs = [] #this variable will hold a list of dfs that will be iterated through to store predictions from each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 0\n",
    "learn_1 = cnn_learner(data, models.densenet161, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "Model_Path = Path('/kaggle/input/densenet161-with-tiles-progressive-resize-448/')\n",
    "learn_1.model_dir = Model_Path\n",
    "learn_1.load('checkpoint-5');\n",
    "Model_Path = Path('/kaggle/working/')\n",
    "learn_1.model_dir = Model_Path\n",
    "\n",
    "learners += [learn_1]\n",
    "\n",
    "learn_df_1 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "learner_dfs += [learn_df_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_2 = cnn_learner(data, models.vgg16_bn, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/with-tiles-progressive-resize-448/')\n",
    "# learn_2.model_dir = Model_Path\n",
    "# learn_2.load('checkpoint-5')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_2.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_2]\n",
    "\n",
    "# learn_df_2 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new tiles panda 718 model 1\n",
    "learn_2 = cnn_learner(data, models.vgg16_bn, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "Model_Path = Path('/kaggle/input/new-tiles-panda-challenge-with-fastai-718')\n",
    "learn_2.model_dir = Model_Path\n",
    "learn_2.load('checkpoint-3')\n",
    "Model_Path = Path('/kaggle/working/')\n",
    "learn_2.model_dir = Model_Path\n",
    "\n",
    "learners += [learn_2]\n",
    "\n",
    "learn_df_2 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "learner_dfs += [learn_df_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_3 = cnn_learner(data_512, models.vgg16_bn, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/panda-models/')\n",
    "# learn_3.model_dir = Model_Path\n",
    "# learn_3.load('checkpoint-3')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_3.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_3]\n",
    "\n",
    "# learn_df_3 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new tiles panda 719 model 2\n",
    "# learn_3 = cnn_learner(data, models.vgg16_bn, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/fork-of-new-tiles-panda-challenge-with-fastai-719')\n",
    "# learn_3.model_dir = Model_Path\n",
    "# learn_3.load('checkpoint-3')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_3.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_3]\n",
    "\n",
    "# learn_df_3 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_4 = cnn_learner(data, models.densenet161, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/densenet161-with-tiles-progressive-resize-448/')\n",
    "# learn_4.model_dir = Model_Path\n",
    "# learn_4.load('checkpoint-6')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_4.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_4]\n",
    "\n",
    "# learn_df_4 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3\n",
    "# learn_5 = cnn_learner(data, models.vgg16_bn, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/with-tiles-progressive-resize-448/')\n",
    "# learn_5.model_dir = Model_Path\n",
    "# learn_5.load('checkpoint-4')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_5.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_5]\n",
    "\n",
    "# learn_df_5 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_6 = cnn_learner(data, models.resnet50, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/resnet-with-tiles-progressive-resize')\n",
    "# learn_6.model_dir = Model_Path\n",
    "# learn_6.load('checkpoint-6')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_6.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_6]\n",
    "\n",
    "# learn_df_6 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 4\n",
    "learn_7 = cnn_learner(data_686, models.densenet169, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "Model_Path = Path('/kaggle/input/densenet169size686/')\n",
    "learn_7.model_dir = Model_Path\n",
    "learn_7.load('dense169-checkpoint-4')\n",
    "Model_Path = Path('/kaggle/working/')\n",
    "learn_7.model_dir = Model_Path\n",
    "\n",
    "learners += [learn_7]\n",
    "\n",
    "learn_df_7 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "learner_dfs += [learn_df_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 5\n",
    "learn_8 = cnn_learner(data_686, models.densenet169, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "Model_Path = Path('/kaggle/input/densenet169size686/')\n",
    "learn_8.model_dir = Model_Path\n",
    "learn_8.load('dense169-checkpoint-5')\n",
    "Model_Path = Path('/kaggle/working/')\n",
    "learn_8.model_dir = Model_Path\n",
    "\n",
    "learners += [learn_8]\n",
    "\n",
    "learn_df_8 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "learner_dfs += [learn_df_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_9 = cnn_learner(data_686, models.resnet50, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/densenet169size686/')\n",
    "# learn_9.model_dir = Model_Path\n",
    "# learn_9.load('resnet50-checkpoint-5')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_9.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_9]\n",
    "\n",
    "# learn_df_9 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_10 = cnn_learner(data_784, models.densenet201, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/pandas-size-784-models/')\n",
    "# learn_10.model_dir = Model_Path\n",
    "# learn_10.load('dense201-checkpoint-5')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_10.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_10]\n",
    "\n",
    "# learn_df_10 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_11 = cnn_learner(data_784, models.densenet201, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/pandas-size-784-models/')\n",
    "# learn_11.model_dir = Model_Path\n",
    "# learn_11.load('dense201-checkpoint-4')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_11.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_11]\n",
    "\n",
    "# learn_df_11 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn_12 = cnn_learner(data_784, models.resnet101, metrics=accuracy , pretrained=False) #resnet101, densenet161, vgg16_bn\n",
    "# Model_Path = Path('/kaggle/input/pandas-size-784-models/')\n",
    "# learn_12.model_dir = Model_Path\n",
    "# learn_12.load('resnet101-checkpoint-2')\n",
    "# Model_Path = Path('/kaggle/working/')\n",
    "# learn_12.model_dir = Model_Path\n",
    "\n",
    "# learners += [learn_12]\n",
    "\n",
    "# learn_df_12 = pd.DataFrame(columns=['id', 'grade_1', 'grade_2', 'grade_3', 'grade_4', 'grade_5'])\n",
    "# learner_dfs += [learn_df_12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "i\n",
      "i\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "# This cell is just to confirm all models where added succesfully\n",
    "\n",
    "for l in learners:\n",
    "    print('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the output directory for new images\n",
    "\n",
    "try:\n",
    "    os.mkdir('resized-test')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<a id=\"part-two\"></a>\n",
    "# Image Preprocessing:\n",
    "The cell below contains the code which is used to preprocess the .tiff files into .jpeg images.\n",
    "\n",
    "[return to Table of Contents](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(image):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image                  numpy.array   multi-dimensional array of the form WxHxC\n",
    "    \n",
    "    Returns:\n",
    "        ratio_white_pixels     float         ratio of white pixels over total pixels in the image \n",
    "    \"\"\"\n",
    "    width, height = image.shape[0], image.shape[1]\n",
    "    num_pixels = width * height\n",
    "    \n",
    "    num_white_pixels = 0\n",
    "    \n",
    "    summed_matrix = np.sum(image, axis=-1)\n",
    "    # Note: A 3-channel white pixel has RGB (255, 255, 255)\n",
    "    num_white_pixels = np.count_nonzero(summed_matrix > 620)\n",
    "    ratio_white_pixels = num_white_pixels / num_pixels\n",
    "    \n",
    "    green_concentration = np.mean(image[1])\n",
    "    blue_concentration = np.mean(image[2])\n",
    "    \n",
    "    return ratio_white_pixels, green_concentration, blue_concentration\n",
    "\n",
    "def select_k_best_regions(regions, k=20):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        regions               list           list of 2-component tuples first component the region, \n",
    "                                             second component the ratio of white pixels\n",
    "                                             \n",
    "        k                     int            number of regions to select\n",
    "    \"\"\"\n",
    "    regions = [x for x in regions if x[3] > 180 and x[4] > 180]\n",
    "    k_best_regions = sorted(regions, key=lambda tup: tup[2])[:k]\n",
    "    return k_best_regions\n",
    "\n",
    "def get_k_best_regions(coordinates, image, window_size=1024):#window size 512 is default\n",
    "    regions = {}\n",
    "    for i, tup in enumerate(coordinates):\n",
    "        x, y = tup[0], tup[1]\n",
    "        regions[i] = image[x : x+window_size, y : y+window_size, :]\n",
    "    \n",
    "    return regions\n",
    "\n",
    "def generate_patches(slide_path, window_size=200, stride=256, k=20):#stride 128\n",
    "    \n",
    "    image = skimage.io.MultiImage(slide_path)[-2]\n",
    "    image = np.array(image)\n",
    "    \n",
    "    max_width, max_height = image.shape[0], image.shape[1]\n",
    "    regions_container = []\n",
    "    i = 0\n",
    "    \n",
    "    while window_size + stride*i <= max_height:\n",
    "        j = 0\n",
    "        \n",
    "        while window_size + stride*j <= max_width:            \n",
    "            x_top_left_pixel = j * stride\n",
    "            y_top_left_pixel = i * stride\n",
    "            \n",
    "            patch = image[\n",
    "                x_top_left_pixel : x_top_left_pixel + window_size,\n",
    "                y_top_left_pixel : y_top_left_pixel + window_size,\n",
    "                :\n",
    "            ]\n",
    "            \n",
    "            ratio_white_pixels, green_concentration, blue_concentration = compute_statistics(patch)\n",
    "            \n",
    "            region_tuple = (x_top_left_pixel, y_top_left_pixel, ratio_white_pixels, green_concentration, blue_concentration)\n",
    "            regions_container.append(region_tuple)\n",
    "            \n",
    "            j += 1\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    k_best_region_coordinates = select_k_best_regions(regions_container, k=k)\n",
    "    k_best_regions = get_k_best_regions(k_best_region_coordinates, image, window_size)\n",
    "    \n",
    "    return image, k_best_region_coordinates, k_best_regions\n",
    "\n",
    "def display_images(regions, title):\n",
    "    fig, ax = plt.subplots(5, 4, figsize=(15, 15))\n",
    "    \n",
    "    for i, region in regions.items():\n",
    "        ax[i//4, i%4].imshow(region)\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    \n",
    "def glue_to_one_picture(image_patches, window_size=200, k=32):\n",
    "    side = int(np.sqrt(k))\n",
    "    image = np.zeros((side*window_size, side*window_size, 3), dtype=np.int16)\n",
    "        \n",
    "    for i, patch in image_patches.items():\n",
    "        x = i // side\n",
    "        y = i % side\n",
    "        image[\n",
    "            x * window_size : (x+1) * window_size,\n",
    "            y * window_size : (y+1) * window_size,\n",
    "            :\n",
    "        ] = patch\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The cell below contains the values by which the images are preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 200\n",
    "STRIDE = 100\n",
    "K = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<a id=\"part-three\"></a>\n",
    "# Inference function:\n",
    "The function below iterates through each of the files in the test dataframe, first preprocessing the images, then running inference on each image by each model, and taking the averaged result. Since we iterate through the images one at a time there isn't a significant advantage to running inference on a GPU over a CPU, this notebook we ran with a CPU to conserve Kaggle's GPU quota. \n",
    "\n",
    "[return to Table of Contents](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filler refers to what value is returned if the models fail to produce a valid inference for a particular case.\n",
    "# 0 is the default for production cases, -1 if what we use for testing to see where errors are occurring\n",
    "def inference_rt(data_dir, df, filler=0, evaluation_mode=False):\n",
    "    df['isup_grade'] = pd.Series([np.NaN for x in df['image_id']], index=df.index)\n",
    "    lst = []\n",
    "    for i in df['image_id']:\n",
    "        try:\n",
    "            url = data_dir + i + '.tiff'\n",
    "            image, best_coordinates, best_regions = generate_patches(url, window_size=WINDOW_SIZE, stride=STRIDE, k=K)\n",
    "            glued_image = glue_to_one_picture(best_regions, window_size=WINDOW_SIZE, k=K)\n",
    "            cv2.imwrite(i+\".jpeg\", glued_image)\n",
    "            img = open_image('/kaggle/working/'+i+'.jpeg')\n",
    "            s_1 = []\n",
    "            s_2 = []\n",
    "            s_3 = []\n",
    "            s_4 = []\n",
    "            s_5 = []\n",
    "            s_all = [s_1, s_2, s_3, s_4, s_5]\n",
    "            for l in learners:\n",
    "                pred_class,pred_idx,outputs = l.predict(img)\n",
    "                s_1 += [float(outputs[0])]\n",
    "                s_2 += [float(outputs[1])]\n",
    "                s_3 += [float(outputs[2])]\n",
    "                s_4 += [float(outputs[3])]\n",
    "                s_5 += [float(outputs[4])]\n",
    "            count = 0\n",
    "            for s in s_all:\n",
    "                s_all[count] = round(np.mean(s))\n",
    "                count+=1\n",
    "            _ = sum(s_all)\n",
    "            df['isup_grade'].loc[df['image_id'] == i] = int(_)\n",
    "        except:\n",
    "            df['isup_grade'].loc[df['image_id'] == i] = filler\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_submission['isup_grade'].loc[df['image_id'] == i] = filler"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Quadratic Weighted Kappa Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def quadratic_kappa(actuals, preds, N=6):\n",
    "    \"\"\"This function calculates the Quadratic Kappa Metric used for Evaluation in the PetFinder competition\n",
    "    at Kaggle. It returns the Quadratic Weighted Kappa metric score between the actual and the predicted values \n",
    "    of adoption rating.\"\"\"\n",
    "    w = np.zeros((N,N))\n",
    "    O = confusion_matrix(actuals, preds)\n",
    "    for i in range(len(w)): \n",
    "        for j in range(len(w)):\n",
    "            w[i][j] = float(((i-j)**2)/(N-1)**2)\n",
    "    \n",
    "    act_hist=np.zeros([N])\n",
    "    for item in actuals: \n",
    "        act_hist[item]+=1\n",
    "    \n",
    "    pred_hist=np.zeros([N])\n",
    "    for item in preds: \n",
    "        pred_hist[item]+=1\n",
    "                         \n",
    "    E = np.outer(act_hist, pred_hist);\n",
    "    E = E/E.sum();\n",
    "    O = O/O.sum();\n",
    "    \n",
    "    num=0\n",
    "    den=0\n",
    "    for i in range(len(w)):\n",
    "        for j in range(len(w)):\n",
    "            num+=w[i][j]*O[i][j]\n",
    "            den+=w[i][j]*E[i][j]\n",
    "    return (1 - (num/den))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<a id=\"part-four\"></a>\n",
    "# Run Inference!\n",
    "\n",
    "When running this notebook normally the `if os.path.exists('../input/prostate-cancer-grade-assessment/test_images'):` will return false, when submitting the notebook to the competition this statement will return true. This codeblock will run each of the test images through preprocessing, run inference, and record the outputs to a submission dataframe.\n",
    "\n",
    "The else block will perform the same task as above, however it will run it on a sample of the training dataset (sample size based on `evaluation_cases`). The purpose of this is to evaluate the performance of the models, and check for errors. The output dataframe has the predicted values in the 'isup_grade' column and the 'actual' column has the actual values. This will also show the quadratic weighted kappa score on the training set, setting `evaluation_casses` to 1000 tends to get results close to the score on the test data.\n",
    "\n",
    "[return to Table of Contents](#ToC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation inference!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002a4db09dad406c85505a00fb6f6144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>003046e27c8ead3e3db155780dc5498</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0032bfa835ce0f43a92ae0bbab6871cb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003a91841da04a5a31f808fb5c21538a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>003d4dd6bd61221ebc0bfb9350db333f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00412139e6b04d1e1cee8421f38f6e90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>004391d48d58b18156f811087cd38abf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>004dd32d9cd167d9cc31c13b704498af</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>004f6b3a66189b4e88b6a01ba19d7d31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>005e66f06bce9c2e49142536caf2f6</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0068d4c7529e34fd4c9da863ce01a161</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>006f4d8d3556dd21f6424202c2d294a9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>006f6aa35a78965c92fffd1fbd53a058</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>007433133235efc27a39f11df6940829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0076bcb66e46fb485f5ba432b9a1fe8a</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id  isup_grade  actual\n",
       "0   0005f7aaab2800f6170c399693a96917           0       0\n",
       "1   000920ad0b612851f8e01bcc880d9b3d           0       0\n",
       "2   0018ae58b01bdadc8e347995b69f99aa           4       4\n",
       "3   001c62abd11fa4b57bf7a6c603a11bb9           4       4\n",
       "4   001d865e65ef5d2579c190a0e0350d8f           0       0\n",
       "5   002a4db09dad406c85505a00fb6f6144           1       0\n",
       "6    003046e27c8ead3e3db155780dc5498          -1       1\n",
       "7   0032bfa835ce0f43a92ae0bbab6871cb           1       1\n",
       "8   003a91841da04a5a31f808fb5c21538a           1       1\n",
       "9   003d4dd6bd61221ebc0bfb9350db333f           1       1\n",
       "10  00412139e6b04d1e1cee8421f38f6e90           0       0\n",
       "11  004391d48d58b18156f811087cd38abf           1       1\n",
       "12  004dd32d9cd167d9cc31c13b704498af           2       1\n",
       "13  004f6b3a66189b4e88b6a01ba19d7d31           1       1\n",
       "14    005e66f06bce9c2e49142536caf2f6          -1       1\n",
       "15  0068d4c7529e34fd4c9da863ce01a161           1       3\n",
       "16  006f4d8d3556dd21f6424202c2d294a9           0       0\n",
       "17  006f6aa35a78965c92fffd1fbd53a058           3       3\n",
       "18  007433133235efc27a39f11df6940829           0       0\n",
       "19  0076bcb66e46fb485f5ba432b9a1fe8a           4       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadratic Weighted Kappa:  0.85\n",
      "CPU times: user 3min 52s, sys: 10.3 s, total: 4min 2s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluation_cases = 20 # number of cases to check when running validation\n",
    "\n",
    "if os.path.exists('../input/prostate-cancer-grade-assessment/test_images'):\n",
    "    data_dir = '../input/prostate-cancer-grade-assessment/test_images/'\n",
    "    print('inference!')\n",
    "    df_out = inference_rt(data_dir, test_df)\n",
    "    df_out['isup_grade'] = df_out['isup_grade'].astype(int)\n",
    "    sample_submission = df_out[['image_id','isup_grade']].copy()\n",
    "else:\n",
    "    data_dir = '../input/prostate-cancer-grade-assessment/train_images/'\n",
    "    print('Evaluation inference!')\n",
    "    train_sample = train_isup.copy()\n",
    "    train_sample['image_id'] = pd.Series([x.rstrip('.jepg') for x in train_sample.id], index=train_sample.index) #train_9k['id'].rstrip('.jepg')\n",
    "    train_sample = train_sample[['image_id', 'isup_grade']].head(evaluation_cases)\n",
    "    train_eval = inference_rt(data_dir, train_sample, filler=-1)\n",
    "    train_eval['actual'] = train_isup['isup_grade'].head(evaluation_cases)\n",
    "    train_eval['isup_grade'] = train_eval['isup_grade'].astype(int)\n",
    "    sample_submission = train_eval[['image_id','isup_grade']].copy()\n",
    "    display(train_eval)\n",
    "    print('Quadratic Weighted Kappa: ', quadratic_kappa(train_eval['isup_grade'].astype(int), train_eval['actual'].astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>isup_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005f7aaab2800f6170c399693a96917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000920ad0b612851f8e01bcc880d9b3d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0018ae58b01bdadc8e347995b69f99aa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001c62abd11fa4b57bf7a6c603a11bb9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001d865e65ef5d2579c190a0e0350d8f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002a4db09dad406c85505a00fb6f6144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>003046e27c8ead3e3db155780dc5498</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0032bfa835ce0f43a92ae0bbab6871cb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003a91841da04a5a31f808fb5c21538a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>003d4dd6bd61221ebc0bfb9350db333f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00412139e6b04d1e1cee8421f38f6e90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>004391d48d58b18156f811087cd38abf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>004dd32d9cd167d9cc31c13b704498af</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>004f6b3a66189b4e88b6a01ba19d7d31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>005e66f06bce9c2e49142536caf2f6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0068d4c7529e34fd4c9da863ce01a161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>006f4d8d3556dd21f6424202c2d294a9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>006f6aa35a78965c92fffd1fbd53a058</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>007433133235efc27a39f11df6940829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0076bcb66e46fb485f5ba432b9a1fe8a</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id  isup_grade\n",
       "0   0005f7aaab2800f6170c399693a96917           0\n",
       "1   000920ad0b612851f8e01bcc880d9b3d           0\n",
       "2   0018ae58b01bdadc8e347995b69f99aa           4\n",
       "3   001c62abd11fa4b57bf7a6c603a11bb9           4\n",
       "4   001d865e65ef5d2579c190a0e0350d8f           0\n",
       "5   002a4db09dad406c85505a00fb6f6144           1\n",
       "6    003046e27c8ead3e3db155780dc5498          -1\n",
       "7   0032bfa835ce0f43a92ae0bbab6871cb           1\n",
       "8   003a91841da04a5a31f808fb5c21538a           1\n",
       "9   003d4dd6bd61221ebc0bfb9350db333f           1\n",
       "10  00412139e6b04d1e1cee8421f38f6e90           0\n",
       "11  004391d48d58b18156f811087cd38abf           1\n",
       "12  004dd32d9cd167d9cc31c13b704498af           2\n",
       "13  004f6b3a66189b4e88b6a01ba19d7d31           1\n",
       "14    005e66f06bce9c2e49142536caf2f6          -1\n",
       "15  0068d4c7529e34fd4c9da863ce01a161           1\n",
       "16  006f4d8d3556dd21f6424202c2d294a9           0\n",
       "17  006f6aa35a78965c92fffd1fbd53a058           3\n",
       "18  007433133235efc27a39f11df6940829           0\n",
       "19  0076bcb66e46fb485f5ba432b9a1fe8a           4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Submit to competition:\n",
    "To submit the notebook to the competition and evaluate, first commit the notebook, then from the committed draft go to the outputs section, select 'submission.csv' and click submit to competition.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
